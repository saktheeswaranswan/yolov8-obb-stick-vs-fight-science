# -*- coding: utf-8 -*-
"""stickgunroddatss.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DU3guMUDMeyKEoFVbuzXm-0ewLiPp6G1

[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)

# How to Train a YOLOv8 Oriented Bounding Boxes Model

---

[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/train-yolov8-obb-model/)
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)

Ultralytics YOLOv8 is the latest version of the YOLO (You Only Look Once) object detection and image segmentation model developed by Ultralytics.

In this guide, we will walk through how to train a YOLOv8 oriented bounding box detection model.

If you notice that our notebook behaves incorrectly, let us know by [opening an issue on the Roboflow Notebooks repository](https://github.com/roboflow/notebooks/issues).

## Accompanying Blog Post

We recommend that you follow along in this notebook while reading our [YOLOv8 oriented bounding box training blog post](https://blog.roboflow.com/train-yolov8-obb-model/).

## Pro Tip: Use GPU Acceleration

If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.

## Steps in this Tutorial

In this tutorial, we are going to cover:

- Checking that our Colab environment has a GPU
- Installing YOLOv8
- Preparing a dataset
- Training a YOLOv8 OBB model
- Running inference on our model

Without further ado, let's get started!

## Before you start

Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`.
"""

!nvidia-smi

import os
HOME = os.getcwd()
print(HOME)

"""## Install YOLOv8

To install YOL0v8, run the following command:
"""

!pip install ultralytics==8.2.103 -q

# prevent ultralytics from tracking your activity
!yolo settings sync=False

import ultralytics
ultralytics.checks()

"""Now, we can import YOLOv8 into our Notebook:"""

from ultralytics import YOLO

from IPython.display import display, Image

"""## Roboflow Universe

Need data for your project? Check out Roboflow Universe, a repository of open source computer vision datasets. You can export any dataset labeled for instance segmentation as a YOLOv8 Oriented Bounding Boxes dataset for use in training a YOLOv8 Oriented Bounding Boxes model.

[![Roboflow Universe](https://media.roboflow.com/notebooks/template/uni-banner-frame.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672878480290)](https://universe.roboflow.com/)

## Prepare a custom¬†dataset

Building a custom dataset can be a painful process. It might take dozens or even hundreds of hours to collect images, label them, and export them in the proper format. Fortunately, Roboflow makes this process as straightforward and fast as possible. Let us show you how!

### Step 1: Creating project

Before you start, you need to create a Roboflow [account](https://app.roboflow.com/login). Once you do that, you can create a new project in the Roboflow [dashboard](https://app.roboflow.com/). Choose "Object Detection" as your project type.

<img src="https://media.roboflow.com/obb-tutorial/create.png" alt="Object detection selected on the Roboflow Create Project pop up" height="300" />

### Step 2: Uploading images

Next, add the data to your newly created project. You can do it via API or through our [web interface](https://docs.roboflow.com/adding-data/object-detection).

If you drag and drop a directory with a dataset in a supported format, the Roboflow dashboard will automatically read the images and annotations together.

<img src="https://media.roboflow.com/obb-tutorial/upload.png" alt="Uploading images to Roboflow" height="300" />

### Step 3: Label Data

If you only have images, you can label them with oriented bounding boxes in [Roboflow Annotate](https://docs.roboflow.com/annotate).

**To label an oriented bounding box, use our polygon annotation tool.**

You can also take an existing segmentation dataset from your workspace or Roboflow Universe and export it as OBB.

<img src="https://media.roboflow.com/obb-tutorial/annotate.png" alt="Annotate an image" height="300" />

### Step 4: Generate new dataset version

Now that we have our images and annotations added, we can Generate a Dataset Version. When Generating a Version, you may elect to add preprocessing and augmentations. This step is completely optional, however, it can allow you to significantly improve the robustness of your model.

<img src="https://media.roboflow.com/keypoint/version.png" alt="Generate a dataset version" height="300" />

### Step 5: Export dataset

Once the dataset version is generated, we can download it for use in training a model.

![Generate a dataset version](https://media.roboflow.com/keypoint/export.png)
"""

# Commented out IPython magic to ensure Python compatibility.
!mkdir -p {HOME}/datasets
# %cd {HOME}/datasets

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="duI2P016ViyIHtg9ER5z")
project = rf.workspace("violence-detection-2").project("gun-knife-stick-detection")
version = project.version(5)
dataset = version.download("yolov8-obb")

import yaml

with open(f'{dataset.location}/data.yaml', 'r') as f:
    data = yaml.safe_load(f)
data['train'] = '/content/datasets/Stick/rod-Detection-4/train/images'
data['val'] = '/content/datasets/Stick/rod-Detection-4/valid/images'
data['test'] = '/content/datasets/Stick/rod-Detection-4/test/images'
if 'path' in data:
  del data['path']
with open(f'{dataset.location}/data.yaml', 'w') as f:
    yaml.dump(data, f, sort_keys=False)

"""## Train a YOLOv8 OBB Object Detection Model

With our dataset downloaded, we can now train a YOLOv8 OBB object detection model. Run the code snippet below to start training your model:
"""

!wget https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x-obb.pt

# Download YOLOv8x-OBB model weights
!wget https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x-obb.pt -O yolov8x-obb.pt

!pip install --upgrade --force-reinstall numpy

# Re-align NumPy + Torch + Ultralytics
!pip install --upgrade --force-reinstall numpy
!pip install --upgrade --force-reinstall torch torchvision torchaudio
!pip install --upgrade --force-reinstall ultralytics

!pip install -U ultralytics

# Upgrade NumPy first
!pip install --upgrade --force-reinstall numpy

# Upgrade Torch stack to match
!pip install --upgrade --force-reinstall torch torchvision torchaudio

# Upgrade Ultralytics
!pip install --upgrade --force-reinstall ultralytics

New https://pypi.org/project/ultralytics/8.3.196 available üòÉ Update with 'pip install -U ultralytics'
Ultralytics YOLOv8.2.103 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)

---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

/tmp/ipython-input-467457201.py in <cell line: 0>()
      2
      3 model = YOLO('/content/datasets/yolov8x-obb.pt')
----> 4 results = model.train(data=f"{dataset.location}/data.yaml", epochs=100, imgsz=640)

6 frames

/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py in <module>
      1 from .bit_generator import BitGenerator
----> 2 from .mtrand import RandomState
      3 from ._philox import Philox
      4 from ._pcg64 import PCG64, PCG64DXSM
      5 from ._sfc64 import SFC64

numpy/random/mtrand.pyx in init numpy.random.mtrand()

ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject

from ultralytics import YOLO

model = YOLO('/content/datasets/yolov8x-obb.pt')

# ‚úÖ wrap your path in quotes:
results = model.train(
    data="/content/datasets/Gun-Knife-Stick-Detection-5/data.yaml",
    epochs=80,
    imgsz=320
)

# 1Ô∏è‚É£ Zip the folder (this will create train8.zip in /content)
!zip -r /content/runs/obb/train.zip /content/runs/obb/train

from ultralytics import YOLO

# 1Ô∏è‚É£ Load your trained model (best.pt)
model = YOLO('/content/runs/obb/train/weights/best.pt')

# 2Ô∏è‚É£ Run OBB inference on the video
results = model.predict(
    source='/content/veera.mp4'  , # input video
    task='obb',                     # explicitly tell YOLO it's OBB task
    save=True,                      # save output video
    save_txt=True,                  # optional: save txt annotations
    conf=0.48                       # confidence threshold, tweak if needed
)

# 3Ô∏è‚É£ The output video will be saved inside:
# /content/runs/obb/predict*/ (first predict run = predict, then predict2 etc.)

!pip install yt-dlp

# install yt-dlp first if not already installed
!pip install -q yt-dlp

# download the video as mp4 into /content
!yt-dlp -f mp4 -o "/content/%(title)s.%(ext)s" "https://www.youtube.com/watch?v=E6wz3Xh1Vmc"

import glob, os

# convert YOLO (xc,yc,w,h) to OBB with 4 corners (axis-aligned rectangle)
def yolo_to_obb(xc, yc, w, h):
    x1 = xc - w/2
    y1 = yc - h/2
    x2 = xc + w/2
    y2 = yc - h/2
    x3 = xc + w/2
    y3 = yc + h/2
    x4 = xc - w/2
    y4 = yc + h/2
    return x1,y1,x2,y2,x3,y3,x4,y4

label_paths = glob.glob('/content/datasets/Stick/rod-Detection-4/valid/labels/*.txt')
for label_path in label_paths:
    with open(label_path, 'r') as f:
        lines = f.read().strip().splitlines()

    new_lines = []
    for line in lines:
        parts = line.strip().split()
        if len(parts) == 5:  # detect style
            cls = int(parts[0])
            xc,yc,w,h = map(float, parts[1:])
            x1,y1,x2,y2,x3,y3,x4,y4 = yolo_to_obb(xc,yc,w,h)
            new_lines.append(f"{cls} {x1} {y1} {x2} {y2} {x3} {y3} {x4} {y4}")
        else:
            # already OBB, just copy
            new_lines.append(line)

    with open(label_path, 'w') as f:
        f.write('\n'.join(new_lines))

https://www.youtube.com/watch?v=rTZ2J6kAZJs
Group fight | silambam

https://www.youtube.com/watch?v=Sn7KYB9Pv3M

https://www.youtube.com/watch?v=Ceqqq27UWWM

https://www.youtube.com/watch?v=Ceqqq27UWWM
https://www.youtube.com/watch?v=c5I_dgP8zKQ
https://www.youtube.com/watch?v=c5I_dgP8zKQ

"""Your model will train for 100 epochs. After training, you can run test your model using an image from your test set.

## Test the OBB Object Detection Model

Let's test our OBB detection model on an image:
"""

model = YOLO('runs/obb/train/weights/best.pt')

import os
import random

random_file = random.choice(os.listdir(f"{dataset.location}/test/images"))
file_name = os.path.join(f"{dataset.location}/test/images", random_file)

results = model(file_name)

print(results[0])

"""We can visualize our oriented bounding box predictions using the following code:"""

!pip install supervision==0.24.0 -q

import supervision as sv
import cv2

detections = sv.Detections.from_ultralytics(results[0])

oriented_box_annotator = sv.OrientedBoxAnnotator()
annotated_frame = oriented_box_annotator.annotate(
    scene=cv2.imread(file_name),
    detections=detections
)

annotated_frame = sv.resize_image(
    annotated_frame,
    resolution_wh=(900, 900),
    keep_aspect_ratio=True
)
sv.cv2_to_pillow(annotated_frame)

"""Our model successfully identified the location of solar panels in the image. All solar panels have an oriented bounding box that fit the panel closely.

## üèÜ Congratulations

### Learning Resources

Roboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:

- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.
- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.
- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.
- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.

### Convert data formats

Roboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.

### Connect computer vision to your project logic

[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections.
"""